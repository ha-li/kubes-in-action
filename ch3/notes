to get the full yaml description of a pod
 > kubectl get pod -o yaml

to outline the pod spec
 > kubectl explain pods

for specifics of the spec
 > kubectl explain pod.spec

to create a pod from a yaml spec
 > kubectl create -f <file spec>
 > kubectl create -f kubia-manual.yaml

to get the full description after creation
 > kubectl get pod <pod name> -o yaml/json

to get the logs of kubernetes pod
 > kubectl logs <pod-name>
   kubectl logs kubia-manual

  logs are rotated daily and when they reach 10 MB. kubectl logs only show current log file.
if you pod container multiple containers, you have to specify the container name
 > kubectl logs <pod-name> -c <container>
   kubectl logs kubia-manual -c kubia

port forwarding
 > kubectl port-forward <pod-name> port1:port2
   will forward port1 of your machine to port2 of your pod
   to now in a new terminal, use curl localhost:port1 to hit the pods port2


Labels

-a key value pair attachable to resources that can then be used to select resources
 using label selectors; kinda like tags in aws
-a resource can have more than one label as long as the keys of the labels are unique 
 within that resource
-usually attach a label to a resource when you create them, but labels can be
 added/modified even after the resource has been created, without the need to 
 recreate the resource.

 aside - a canary release is when you deploy a new version of an application next to the
 stable version, and only let a small fraction of users hit the canary version to see
 how it behaves before rolling it out to all users, preventing a large exposure if
 the release is unstable

-labels will be visible to all person with access to that cluster
 > kubectl get pods --show-labels

-can also specify the labels you are interested in, and all pods will be returned with
 labels in speciial columns
 > kubectl get pods -L creation_method,env

-you can also modify the labels of existing pods
 > kubectl label pod kubia-manual creation_method=manual
   this will modify the creation_method label of kubia-manual to be manual

-if the pod already has that label, then you have to specify to overwrite it
 > kubectl label pod kubia-manual-v2 env=debug --overwrite

-to select pods based on labels
 > kubectl get pod -l creation_method=manual

-to select pods with a certain label specified, eg if the env label is set
 > kubectl get pod -l env 

-to select pods on a label and also display the labels, you combine both -l and -L
 > kubectl get pod -l env -L creation_method,env

-to select pods that don't have a certain label
 > kubectl get pod -l '!env'

-to select pods based on multiple values
 > kubectl get pod -l creation_method in (prod,dev)
 > kubectl get pod -l creation_method notin (prod,dev)


Using Labels to control pod scheduling
In general you don't want to specify which nodes a pod should be created on, and just allow the kubernetes
cluster to allocate pods based on their resource requirements (eg, x memory, y cpu, z ssd/hdd)
but once in a while you will want to control which node a pod will be scheduled on based on certain 
characteristics of the node and the application requirement, eg deploy to nodes using ssd, 
or deploy on nodes using GPU, etc

to do so, you will need to label your nodes as they get set up
> kubectl label node gke2-aruc-548fea gpu=true

like wise you can select nodes and have them display the labels 
> kubectl get node -l gpu=true -L gpu
  will retrieve nodes where gpu is true, as well as display the gpu label


to specify a pod get deployed to a certain node you need to specify in your yaml manifest
a node selector criteria

 
Each node has a unique label with the key kubernetes.io/hostname which is the actual hostname of the node.
You could potentially use this as a label selector to control your deployment, but in general doing so
would be bad practice because if such a node label does not exist, then the pod will become
unscheduled. 

Don't think in terms of individual nodes, but rather, node features you want to target


Pod Annotations
--------------
Pods and other objects can contain annotations. 
Annotations are key value pairs, similar to labels, but they are not meant to hold identifying information.
They cannot be used to group objects as there are no such thing as annotation selectors.

Annotations hold much more information then labels, and are mainly used by tools.
Some tools will add annotations, and some annotations get added by users.

Annotations are common used when a new feature gets added to kubernetes, before the API is clear
about the feature, as a way to document a feature, and then once the feature is agreed upon by
the community, new fields are added, and the annotation gets deprecated.

A good use of annotation is to add description to each pod or api object so that everyone using the
cluster can quickely get information about each object.

It is a good idea to use namespacing when annotation so that collisions doen't happen
   gecko.com/annotationkey=annoationvalue

An objects annotation will be in the resources metadata section.
To view the objects annotation, you need to objects yaml/json manifest
 > kubectl get pod <pod> -o yaml 


to add an annotation to an existing pod
 > kubectl annotate pod <pod-name> company.com/someannotaion="somevalue"



Kubernetes Namespaces

There will be times when you want to be able to split your objects into separate non-overlapping groups
so that you only perform operations inside one group at a time. This is where namespacing comes into play.
Namespacing provides a scope for object names.

So within different namespaces, objects can have the same name -- this may be useful.
For example in complex systems, you want to split your components into smaller distinct groups.
For example prod/pre-prod environments. So if you have a qal namespace and a prod namespace, the
objects name have the same name in each of those namespaces.

Nodes do not reside in a namespace, they are global and not tied to a namespace.

-to get the name space
 > kubectl get ns

you will see that there is a default namespace, a kube-public and kube-system namespace.

-to get objects within a certain namepace
> kubectl get pod --namespace kube-system

  will return all pods within the kube-system namepsace. It would make sense that objects used to 
run kubernetes will reside in their own namepsace, and don't get returned when you are running
your standard commands (which work for the default namespace), otherwise your the kube-system 
objects would clutter all your return values

Namespaces are just another kubernetes resource, so they get created just like any other object, via
a manifest file:


You can also create namesapces with a command:
 > kubectl create namespace my-namespace

There are rules for object names (RFC 1035 - domain names) but namespaces may not conatin dots.

When creatign objects, if you want to target a namespace, you can either declare the
namespace in the object manifest, or in the create command
> kubectl create -f my-manifest.yaml --namespace custom-namespace

When working objects in a namespace, if you don't specify the namespace, it will be the default
namespace, otherwise you need to specify it as part of your command.

You can switch between namespaces with the command
 > kubectl config set-context $(kubectl config current-context) --namespace <namespace to switch to>
 > kubectl config set-context $(kubectl config current-context) --namespace ass-kick-ns
    which switch to the namespace 'ass-kick-ns' and all kubectl commands will execute in that
    context, until you swtich back to default


Namespaces do not provide isolation of the running objects. Namespace only provides logical group distinction,
but objects can still communicate across namespaces if there is not ioslation.


Deleting Pods
To delete pods
> kubectl delete pod <pod name>, <pod name2>, ...

Kubernetes will send a SIGTERM signal to the process and wait for (30 secs) default time to allow the process
to gracefully shut down. If not, then it will send a SIGTERM signal

You can use the label selector to delete pods with that label
> kubectl delete pod -l creation_method=manual
 will delete all pods created manually

You can delete an entire namespace
> kubectl delete ns <namespace>

You delete all pods in a namespace
> kubectl delete pod --all

anything that was created by a replication controller will attempt to scale up to its desired size
after a delete all command, so you have to delelete the replication controller as well
> kubectl delete all --all
 (this will delete services, rc, pods but will not delete secrets)
