minikube is a binary that allows you to run a single instance kubernetes cluster
-it is great for testing kubernetes and developing apps locally 
best documentation for installing minikube is here
https://github.com/kubernetes/minikube

to start minikube:
   > minikube start

to stop minikube:
   > minikube stop

to ssh into minikube:
   > minikube ssh

to get the dashboard for minikube
   > minikube dashboard

=======================

To interact with Kubernetes, you will need kubectl cli client.
To install kubectl, run:
   > curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl && chmod +x kubectl && sudo mv kubectl /usr/local/bin/

   to see the components of your cluster:
   > kubectl cluster-info

   to see all the nodes in your cluster:
   > kubectl get nodes

   to describe a node
   > kubectl describe node <node-name>

   to run an docker image on kubernetes cluster (for a replication controller)
   > kubectl run kubia --image=haja/kubia --port=8080 --generator=run/v1

   to get all the pods
   > kubectl get pods
     kubectl get pods -o wide (will have the pod ips and the node they are running on)

   to describe a pod
   > kubectl describe pod <pod-name>

   to get the service objects
   > kubectl get services

   to get the number of replication controllers
   > kubectl get rc
 
   to scale the replica pods
   > kubectl scale rc <name> --replicas=3 
      eg: kubectl scale rc kubia --replicas=3   (creates 3 pods)


   to create a load balancer (rc = replicationcontroller) (minikube does not support LoadBalancer service)
   > kubectl expose rc kubia --type=LoadBalancer --name kubia-http

   minikube does not support the LoadBalancer type service, so to get the ip address of the service
   > minikube service kubia-http (kubia-http is the name returned by kubectl get services)

kubernetes does not run individual containers, rather, it runs them inside pods. so containers can
be co-located in pods. 

a node has 1 or more pods.
each pod has its own ip address.
a pod can have 1 or more containner.


Typically when you use kubernetes, you will prepare a manifest (json or yml) file declaring each
component you want to deploy. This manifest will have its own format.

On your own desktop, you can just run kubectl commands to deploy the components.

Typical components will be your load balancer, a replication controller which controls 
your scaling replica and more.

  eg to deploy a replica responsible for deploying a docker image:
  > kubectl run <component name> --image=<image id> --port=<port> --generator=run/v1
    kubectl run kubia --image=haja/kubia --port=8080 --generator=run/v1

    this will deploy a replication contoller naminng it kubia, that will control
    containers built from the image 'haja/kubia', open port 8080.

when you run kubectl run to deploy a node (on some central deployment machine), 
this sends an HTTP request to the Kubernetes API server to create a ReplicationController.
The ReplicationController creates a new pod, which gets scheduled to one of the worker nodes by the Scheduler.
The Kubelet on that node sees a pod was scheduled to it, does a docker pull command to retrive the Docker image and
create a new container and run it.
 ( scheduling means assigning a pod to a node to be run immediately)

even though each pod has it's own ip address


Pods 
Kubernetes components run in pods. Each pod will house 1 or more container.
Each pod will run on exactly 1 node. A node may house multiple pods.
Each pod will have its own ip address.

  +-----------------------------+
  |+-------+ +-------+ +-------+|
  || Pod 1 | | Pod 2 | | Pod 3 || 
  ||       | |       | |       || 
  ||+-----+| |+-----+| |+-----+||
  |||con 1|| ||con 1|| ||con 1|||
  ||+-----+| |+-----+| |+-----+||
  ||       | |       | |       ||
  ||       | |+-----+| |+-----+||
  ||       | ||con 2|| ||con 2|||
  ||       | |+-----+| |+-----+||
  ||       | |+-----+| |       ||
  ||       | ||con 3|| |       ||
  ||       | |+-----+| |       ||
  ||ip x   | | ip y  | | ip z  ||
  |+-------+ +-------+ +-------+|
  | Node 1                      |
  +-----------------------------+

A pod is a group of 1 or more containers that will run together on the same
worker node, and in the same linux namespace (ie they will look like
they are in the same machine because they have the same ip address).

Since they have the same ip address, the container (which typically
only run 1 process per container) must bind to different ports.

Each pod has it's own linux namespace, ip address, hostname, processes.
Each pod functions as a separate logical machine even though they 
are on the same physical machine.

Each pod can run 1 or more containers, and each container will
one house 1 process each, as is typical in a docker environment.

Typical workflow when developing.
1. you develop your app on your machine, create a docker image
   on your local machine
2. check your image into a docker registry
3. kick of your kubectl which will create/spawn a replication 
   controller to create a pod on the kubernetes cluster
4. the replication controller will pull down the docker image
   from the registry and create a pod on the cluster 
   from the resulting container.

You will also need to create a service object (this is typically
associated with a load balancer) which you can connect
to the pod from external to the cluster, by using that load
balancers public ip address.

  > kubectl expose rc kubia --type=LoadBalancer --name=kubia-http

Newly created services can be listed by:
  > kubectl get services
 
minikube does not support loadbalancer services, so the service
will never get an external ip address. but minikube will allow to 
to get the ip and port which you can access the service:
 
  > minikube service <service-name>
    eg minikube service kubia-http


The basic building block in kubernetes is the pod. You never
work directly with the container. But even with pods, you 
don't typically work with them directly, but rather through
a replication controller, which is what is actually responsible
for creating the pods.

The ReplicaitonController is the equivalent of a autoscaling group in AWS.
It is responsible for keeping the correct number of replicas running.
When a pod dies because of a fatal exception, the replication controller
is responsible for bringing it back up.

Pods are ephemeral, they can die, disappear at anytime because the
node they are running on disappears, someone deletes a pod, or
a health pod gets evicted as part of the general maintainance 
of the cluster. When this happens, a replication controller 
will replace the pod with a new pod. This new pod will have its
own ip addres that is differnet from the dying pod.
The fact that the pods are ephemeral means we need to shield
them from the clients, which is where a load balancer comes in play.

When a new service is created, it gets a static ip which will 
never change during the life time of the service. Instead of 
connecting to the pods directly, clients should connect to 
the services through its constant ip address. The load 
balancer will ensure that one of the healthy pods gets the
request regardless of which node the pods are running on.

To scale up or down a kubernetes cluster, you run the command
 > kubectl get replicationcontrollers
to show you how many replicas are.

To change the replica count you run:

  > kubectl scale rc kubia --replicas=3

In a kubernetes cluster, the pods can be expected to be moving 
constantly as the cluster is a dynamic moving system. The service
acts as a load balancer in front of the pods, regardless of whether
it is a singel pod or multiple pods. 

In the kubernetes world, what node your pods are running on is not important.
As long as the node it ends up on can provide the cpu and memory the pod needs,
the pod is happy.

But the get pods command does allow you to see what node a pod is on
just in case you are interested. this is the wide mode

  > kubectl get pods -o wide

You can see the pod info with a describe command:
  
  > kubectl describe pod <pod id>


Kubernete Dashboard
provides a dashboard view of the cluster.
The minikube also provides the same view:

   > minikube dashboard


