-Review of Docker 
-Installing minikube on mac
-


Review of Docker
----------------
-building a docker image
-running a docker image
-exploring inside a docker container
-stopping a container, clean up of stopped containers
-listing docker images + other commands
-pushing images to repos

Building a Docker Image
-----------------------
Create a simple nodejs app called app.js 
and build a docker image from it (Dockerfile)
- call the docker image kubia

 > docker build -t kubia .

 This command will build a container called kubia from the current directory's
 Dockerfile. The Dockerfile of this example uses as its base, node:7
 and adds to it, our app.js at /, and sets its entrypoint as "node app.js"


After the docker image has been build, you should be able to see it on your
host os
 > docker images 
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
kubia               latest              03e2e0d60bec        56 seconds ago      660MB


Running a docker image
----------------------
To run a docker image of busybox:

 > docker run <image> or docker run <image>:<tag>
 > docker run busybox echo "Hello World"


Now run the image:
 > docker run --name kubia-container -p 8080:8080 -d kubia

 This command tells docker to create a container called kubia-container
 from the kubia image in detached mode (-d), with port mapping 8080 inside the
 container to 8080 outside the container (-p 8080:8080).
 
 You should be able to access the app using curl or browser http://localhost:8080
 > curl localhost:8080
 You've hit ...


Exploring Inside a Running Docker Container
-------------------------------------------
You can run a shell inside of a running container:

 > docker exec [OPTIONS] CONTAINER COMMAND [ARGS...]

 eg:
 > docker exec -it kubia-container bash

    You are executing (exec) a command (bash) in interactive mode (-it)
    of the conatiner you named above (kubia-container)

    The -it is actually short hand for two options:
     -i interactive (keep STDIN open, giving you a command prompt)
     -t gives you a pseudo terminal (TTY)


 You can try out other commands like:
 > docker exec kubia-container ls /
  
    This will run "ls /" on the kubia-container in
    regular mode (so the prompt will not be interactive)
    - you should see our app.js in /

 
 Once you get a listing of / you can see the directories inside / also.
 > docker exec kubia-container ls /etc
 
 
 You can also more the contents of /app.js to confirm it is the source
 code we wrote:
 > docker exec kubia-container more /app.js


 You can get a listing of the processes inside the container:
 > docker exec kubia-container ps 


 Or do it interactively:
 > docker exec -it kubia-container bash
 
 This will give you the prompt and then you can run ps:
 root@83acd3921c:/# ps
 root@83acd3921c:/# ps aux

   Both commands should give you a lising of the processes running
   in the container, and if we built the container right, you should
   see node app.js for sure.

 You should also be able to see app.js in your host os (in Linux)
   (in Mac OS, you run docker inside a VirtualBox VM so you have to
    log into your VM to see the app.js of the container in your host
    VM file system)
 

Stopping a Container + Clean up 
-------------------------------
To stop a container:
 > docker stop <container name>
 > docker stop kubia-container

 
To remove a stopped container: 
   docker rm <container>
 > docker rm kubia-container
 

Listing Docker Images on your OS
--------------------------------
You can list all the docker images you currently have by:
 > docker images

You can list your running docker containers by
 > docker ps

You can list stopped docker containers by:
 > docker ps -a

Pushing Images to Image Repository
----------------------------------
To push an image to a repo, you need to tag it first
 > docker tag kubia haja/kubia

Then you can push it
 > docker push haja/kubia


Now on a different machine you can run the pushed image as
 > docker run -p 8080:8080 -d haja/kubia


Setting up a Kubernetes Cluster
-------------------------------

minikube is a binary that allows you to run a single instance kubernetes cluster
-it is great for testing kubernetes and developing apps locally 
best documentation for installing minikube is here
https://github.com/kubernetes/minikube

-on macOs install using brew
     (you need oracle vm virtualbox manager installed before installing minikube)
   > brew cask install minikube

-if you've already installed minikube, and then deleted the image, reinstall 
 requires you to delete minikube then reinstall 
   > minikube stop; minikube delete
   > rm -fr ~/.kube ~/.minikube
   > sudo rm /usr/local/bin/localkube /usr/local/bin/minikube
   > systemctl stop ;*kubelet*.mount'
   > sudo rm -fr /etc/kubernetes
   > brew cask reinstall minikube
   (you'll need to start minikube before the image shows up in the virtualbox manager)

-you also need to install kubectl
   brew install kubectl

to start minikube:
   > minikube start

to stop minikube:
   > minikube stop

to ssh into minikube:
   > minikube ssh

to get the dashboard for minikube
   > minikube dashboard

=======================

To interact with Kubernetes, you will need kubectl cli client.
To install kubectl, run:
   > curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl && chmod +x kubectl && sudo mv kubectl /usr/local/bin/
Or you can install it with brew
   > brew install kubectl

Cluster Components
==================
   to see the components of your cluster:
   > kubectl cluster-info
     This will return the cluster components (Kubernetes master, KubeDNS/CoreDNS, kubernetes-dashboard)
     and their ip address/port info

Nodes
=====

   to see all the nodes in your cluster:
   > kubectl get nodes
     This will return the nodes in your cluster. In your local-run single node minikube cluster, you will
     only see minikube

     NAME        STATUS    ROLE      AGE   VERSION
     minikube    Ready     master    1m    v1.5.10


   to describe a node
   > kubectl describe node <node-name>
     eg kubectl describe node minikube 
     
     This will return a detailed output describing the node such as the role, name, events, etc
    
   to describe all nodes 
   > kubectl describe node

Pods
====
   The most basic unit in kubernetes is a pod. 
   A pod is a separate logical machine. It has its own ip address, hostname, process linux namespace etc
   A pod will have 1 or more containers. Containers in the pod have their own linux namespace.
   Containers on the same pod will appear as though they are running on the same machine (since they
   have the same ip address).


   Usually to create a pod/run an image, you would create a manifest file (yaml/json format) and
   run kubectl create -f <file-name>

   but to create a pod from a image in its simpliest form:

   to run an docker image on kubernetes cluster (for a replication controller)
   > kubectl run kubia --image=haja/kubia --port=8080 --generator=run/v1
        kubia is the pod name
        --image is the docker image name
        --port is the port kubernets opens
        --generator - usually you wouldn't use it because you would use a deployment, but
                      here you're using it so that kubernetes will create a replicationcontroller
                      instead of a deployment

   to get all the pods
   > kubectl get pods
     kubectl get pods -o wide (will have the pod ips and the node they are running on)

     NAME        READY      STATUS     RESTARTS     AGE
     kubia-ksyt  1/1        Running    0            10m

     the ready column gives you the number of pods running in ready out of all
     the status gives the pending/running/created status
     restarts - gives the number of times the pod has been restarted
     age - the age of the pod

   to describe a pod
   > kubectl describe pod <pod-name>
     will return a detailed description of the pod including its namespace, name, labels, start time, etc


When you run kubectl on your local machine with a set of instructions, this instruction set will be
sent to the REST API Server on the master node (master). 

The master node will then schedule one of the worker nodes (node) to pull the docker image from the
docker registry. The worker node will spawn a pod, download the image. After the node is downloaded, 
docker will create a container and run it inside the pod.

The term scheduling means assigning a pod to a node. The pod will get run right away, not some time in
the future as the name schedule would suggest.


Services
========
Services represent things like load balancers

   to get the service objects
   > kubectl get services
    
     NAME          CLUSTER-IP     EXTERNAL-IP     PORT(S)          AGE
     kubernetes    10.34.22.1     <none>          443/TCP          12m
     kubia-http    10.3.234.184   104.230.75.1    8080:31348/TCP   1m

   to create a load balancer 
      (rc = replicationcontroller) (minikube does not support LoadBalancer service)
   > kubectl expose rc kubia --type=LoadBalancer --name kubia-http
     this telss kubectl to expose replicas named kubia through a load balancer service with
     the name kubia-http

   minikube does not support the LoadBalancer type service, so to get the ip address of the service
   > minikube service kubia-http (kubia-http is the name returned by kubectl get services)

ReplicationControllers
======================
ReplicationControlers are the equivaent of ASG in AWS. 
They are responsible for scaling up and down the pods.


   to get the number of replication controllers
   > kubectl get rc
     kubectl get replicationcontroller
     
     NAME         DESIRED       CURRENT       READY        AGE
     kubia        1             1             1            10m

 
   to scale the replica pods, you tell kubectl the desired state, kubectl
   will do the necessary to get to the desired state.
   > kubectl scale rc <name> --replicas=3 
      eg: kubectl scale rc kubia --replicas=3   (creates 3 pods)


kubernetes does not run individual containers, rather, it runs them inside pods. so containers can
be co-located in pods. 

a node has 1 or more pods.
each pod has its own ip address.
a pod can have 1 or more containner.


Typically when you use kubernetes, you will prepare a manifest (json or yml) file declaring each
component you want to deploy. This manifest will have its own format.

On your own desktop, you can just run kubectl commands to deploy the components.

Typical components will be your load balancer, a replication controller which controls 
your scaling replica and more.

  eg to deploy a replica responsible for deploying a docker image:
  > kubectl run <component name> --image=<image id> --port=<port> --generator=run/v1
    kubectl run kubia --image=haja/kubia --port=8080 --generator=run/v1

    this will deploy a replication contoller naminng it kubia, that will control
    containers built from the image 'haja/kubia', open port 8080.

when you run kubectl run to deploy a node (on some central deployment machine), 
this sends an HTTP request to the Kubernetes API server to create a ReplicationController.
The ReplicationController creates a new pod, which gets scheduled to one of the worker nodes by the Scheduler.
The Kubelet on that node sees a pod was scheduled to it, does a docker pull command to retrive the Docker image and
create a new container and run it.
 ( scheduling means assigning a pod to a node to be run immediately)

even though each pod has it's own ip address


Pods 
Kubernetes components run in pods. Each pod will house 1 or more container.
Each pod will run on exactly 1 node. A node may house multiple pods.
Each pod will have its own ip address.

  +-----------------------------+
  |+-------+ +-------+ +-------+|
  || Pod 1 | | Pod 2 | | Pod 3 || 
  ||       | |       | |       || 
  ||+-----+| |+-----+| |+-----+||
  |||con 1|| ||con 1|| ||con 1|||
  ||+-----+| |+-----+| |+-----+||
  ||       | |       | |       ||
  ||       | |+-----+| |+-----+|| ||       | ||con 2|| ||con 2|||
  ||       | |+-----+| |+-----+||
  ||       | |+-----+| |       ||
  ||       | ||con 3|| |       ||
  ||       | |+-----+| |       ||
  ||ip x   | | ip y  | | ip z  ||
  |+-------+ +-------+ +-------+|
  | Node 1                      |
  +-----------------------------+

A pod is a group of 1 or more containers that will run together on the same
worker node, and in the same linux namespace (ie they will look like
they are in the same machine because they have the same ip address).

Since they have the same ip address, the container (which typically
only run 1 process per container) must bind to different ports.

Each pod has it's own linux namespace, ip address, hostname, processes.
Each pod functions as a separate logical machine even though they 
are on the same physical machine.

Each pod can run 1 or more containers, and each container will
one house 1 process each, as is typical in a docker environment.

Typical workflow when developing.
1. you develop your app on your machine, create a docker image
   on your local machine
2. check your image into a docker registry
3. kick of your kubectl which will create/spawn a replication 
   controller to create a pod on the kubernetes cluster
4. the replication controller will pull down the docker image
   from the registry and create a pod on the cluster 
   from the resulting container.

You will also need to create a service object (this is typically
associated with a load balancer) which you can connect
to the pod from external to the cluster, by using that load
balancers public ip address.

  > kubectl expose rc kubia --type=LoadBalancer --name=kubia-http

Newly created services can be listed by:
  > kubectl get services
 
minikube does not support loadbalancer services, so the service
will never get an external ip address. but minikube will allow to 
to get the ip and port which you can access the service:
 
  > minikube service <service-name>
    eg minikube service kubia-http


The basic building block in kubernetes is the pod. You never
work directly with the container. But even with pods, you 
don't typically work with them directly, but rather through
a replication controller, which is what is actually responsible
for creating the pods.

The ReplicaitonController is the equivalent of a autoscaling group in AWS.
It is responsible for keeping the correct number of replicas running.
When a pod dies because of a fatal exception, the replication controller
is responsible for bringing it back up.

Pods are ephemeral, they can die, disappear at anytime because the
node they are running on disappears, someone deletes a pod, or
a health pod gets evicted as part of the general maintainance 
of the cluster. When this happens, a replication controller 
will replace the pod with a new pod. This new pod will have its
own ip addres that is differnet from the dying pod.
The fact that the pods are ephemeral means we need to shield
them from the clients, which is where a load balancer comes in play.

When a new service is created, it gets a static ip which will 
never change during the life time of the service. Instead of 
connecting to the pods directly, clients should connect to 
the services through its constant ip address. The load 
balancer will ensure that one of the healthy pods gets the
request regardless of which node the pods are running on.

To scale up or down a kubernetes cluster, you run the command
 > kubectl get replicationcontrollers
to show you how many replicas are.

To change the replica count you run:

  > kubectl scale rc kubia --replicas=3

In a kubernetes cluster, the pods can be expected to be moving 
constantly as the cluster is a dynamic moving system. The service
acts as a load balancer in front of the pods, regardless of whether
it is a singel pod or multiple pods. 

In the kubernetes world, what node your pods are running on is not important.
As long as the node it ends up on can provide the cpu and memory the pod needs,
the pod is happy.

But the get pods command does allow you to see what node a pod is on
just in case you are interested. this is the wide mode

  > kubectl get pods -o wide

You can see the pod info with a describe command:
  
  > kubectl describe pod <pod id>


Kubernete Dashboard
provides a dashboard view of the cluster.
The minikube also provides the same view:

   > minikube dashboard


